{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "Runs MNIST training with differential privacy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from opacus import PrivacyEngine\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Precomputed characteristics of the MNIST dataset\n",
    "MNIST_MEAN = 0.1307\n",
    "MNIST_STD = 0.3081\n",
    "delta = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SampleConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 8, 2, padding=3)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 4, 2)\n",
    "#         self.fc1 = nn.Linear(32 * 4 * 4, 32)\n",
    "#         self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x of shape [B, 1, 28, 28]\n",
    "#         x = F.relu(self.conv1(x))  # -> [B, 16, 14, 14]\n",
    "#         x = F.max_pool2d(x, 2, 1)  # -> [B, 16, 13, 13]\n",
    "#         x = F.relu(self.conv2(x))  # -> [B, 32, 5, 5]\n",
    "#         x = F.max_pool2d(x, 2, 1)  # -> [B, 32, 4, 4]\n",
    "#         x = x.view(-1, 32 * 4 * 4)  # -> [B, 512]\n",
    "#         x = F.relu(self.fc1(x))  # -> [B, 32]\n",
    "#         x = self.fc2(x)  # -> [B, 10]\n",
    "#         return x\n",
    "\n",
    "#     def name(self):\n",
    "#         return \"SampleConvNet\"\n",
    "\n",
    "\n",
    "class MnistNet(nn.Module):\n",
    "    \"\"\"Mnist network definition.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialization of the network.\"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Defines the forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            input_data (Tensor): Input data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tensor: Output data\n",
    "        \"\"\"\n",
    "        out = input_data.view(-1, 28 * 28)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        return self.fc3(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, privacy_engine, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    epsilon = privacy_engine.accountant.get_epsilon(delta=delta)\n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta})\"\n",
    "        f\"(Accuracy: {100.0 * correct / len(train_loader.dataset)})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "data_root = \"../mnist\"\n",
    "test_batch_size = 256\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        data_root,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        data_root,\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_results = []\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "sigma = 2.0\n",
    "max_per_sample_grad_norm = 5.0\n",
    "model = MnistNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "\n",
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=test_loader,\n",
    "    noise_multiplier=sigma,\n",
    "    max_grad_norm=max_per_sample_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, privacy_engine, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def train_process(queue, weights, train_loader, privacy_engine, epoch):\n",
    "    print(f\"Training epoch: {epoch}\")\n",
    "\n",
    "    def get_parameters(model):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "    def set_params(model: torch.nn.ModuleList, params):\n",
    "        \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "        params_dict = zip(model.state_dict().keys(), params)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    model = MnistNet()\n",
    "    set_params(model, weights)\n",
    "    model.to(\"cuda:0\")\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "    model, optimizer, train_loader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=test_loader,\n",
    "        noise_multiplier=sigma,\n",
    "        max_grad_norm=max_per_sample_grad_norm,\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    print(f\"Starting Train: {epoch}\")\n",
    "    sys.stdout.flush()\n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    epsilon = privacy_engine.accountant.get_epsilon(delta=delta)\n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta})\"\n",
    "        f\"(Accuracy: {100.0 * correct / len(train_loader.dataset)})\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "    queue.put((get_parameters(model), privacy_engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Process, Queue\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_parameters(model):\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_params(model: torch.nn.ModuleList, params):\n",
    "    \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), params)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "model = MnistNet().to(device)\n",
    "\n",
    "weights = get_parameters(model)\n",
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weights, train_loader, privacy_engine, 0])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weigts, device, privacy_engine, 1])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weigts, device, privacy_engine, 1])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 64, 64]             224\n",
      "              ReLU-2            [-1, 8, 64, 64]               0\n",
      "         MaxPool2d-3            [-1, 8, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           1,168\n",
      "              ReLU-5           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-6           [-1, 16, 16, 16]               0\n",
      "            Conv2d-7           [-1, 16, 16, 16]           2,320\n",
      "              ReLU-8           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-9             [-1, 16, 8, 8]               0\n",
      "           Linear-10                    [-1, 4]           4,100\n",
      "================================================================\n",
      "Total params: 7,812\n",
      "Trainable params: 7,812\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.91\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from pistacchio_simulator.Models.celeba import CelebaNet\n",
    "import torch \n",
    "model = CelebaNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "summary(model, input_size=(3, 64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistacchio-fl-simulator-XKOu9Fs5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
