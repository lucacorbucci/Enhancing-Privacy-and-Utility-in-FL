{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "Runs MNIST training with differential privacy.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from opacus import PrivacyEngine\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Precomputed characteristics of the MNIST dataset\n",
    "MNIST_MEAN = 0.1307\n",
    "MNIST_STD = 0.3081\n",
    "delta = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SampleConvNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 8, 2, padding=3)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, 4, 2)\n",
    "#         self.fc1 = nn.Linear(32 * 4 * 4, 32)\n",
    "#         self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x of shape [B, 1, 28, 28]\n",
    "#         x = F.relu(self.conv1(x))  # -> [B, 16, 14, 14]\n",
    "#         x = F.max_pool2d(x, 2, 1)  # -> [B, 16, 13, 13]\n",
    "#         x = F.relu(self.conv2(x))  # -> [B, 32, 5, 5]\n",
    "#         x = F.max_pool2d(x, 2, 1)  # -> [B, 32, 4, 4]\n",
    "#         x = x.view(-1, 32 * 4 * 4)  # -> [B, 512]\n",
    "#         x = F.relu(self.fc1(x))  # -> [B, 32]\n",
    "#         x = self.fc2(x)  # -> [B, 10]\n",
    "#         return x\n",
    "\n",
    "#     def name(self):\n",
    "#         return \"SampleConvNet\"\n",
    "\n",
    "\n",
    "class MnistNet(nn.Module):\n",
    "    \"\"\"Mnist network definition.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialization of the network.\"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"Defines the forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            input_data (Tensor): Input data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Tensor: Output data\n",
    "        \"\"\"\n",
    "        out = input_data.view(-1, 28 * 28)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        return self.fc3(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, privacy_engine, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    epsilon = privacy_engine.accountant.get_epsilon(delta=delta)\n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta})\"\n",
    "        f\"(Accuracy: {100.0 * correct / len(train_loader.dataset)})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "data_root = \"../mnist\"\n",
    "test_batch_size = 256\n",
    "batch_size = 256\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        data_root,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        data_root,\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "            ]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_results = []\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "sigma = 2.0\n",
    "max_per_sample_grad_norm = 5.0\n",
    "model = MnistNet().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "\n",
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "model, optimizer, train_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=test_loader,\n",
    "    noise_multiplier=sigma,\n",
    "    max_grad_norm=max_per_sample_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, privacy_engine, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def train_process(queue, weights, train_loader, privacy_engine, epoch):\n",
    "    print(f\"Training epoch: {epoch}\")\n",
    "\n",
    "    def get_parameters(model):\n",
    "        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "    def set_params(model: torch.nn.ModuleList, params):\n",
    "        \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "        params_dict = zip(model.state_dict().keys(), params)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    model = MnistNet()\n",
    "    set_params(model, weights)\n",
    "    model.to(\"cuda:0\")\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "    model, optimizer, train_loader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=test_loader,\n",
    "        noise_multiplier=sigma,\n",
    "        max_grad_norm=max_per_sample_grad_norm,\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    print(f\"Starting Train: {epoch}\")\n",
    "    sys.stdout.flush()\n",
    "    for _batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        pred = output.argmax(\n",
    "            dim=1, keepdim=True\n",
    "        )  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    epsilon = privacy_engine.accountant.get_epsilon(delta=delta)\n",
    "    print(\n",
    "        f\"Train Epoch: {epoch} \\t\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"(ε = {epsilon:.2f}, δ = {delta})\"\n",
    "        f\"(Accuracy: {100.0 * correct / len(train_loader.dataset)})\"\n",
    "    )\n",
    "    sys.stdout.flush()\n",
    "    queue.put((get_parameters(model), privacy_engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lcorbucci/.cache/pypoetry/virtualenvs/pistacchio-fl-simulator-XKOu9Fs5-py3.10/lib/python3.10/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfastcep/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m p \u001b[39m=\u001b[39m Process(target\u001b[39m=\u001b[39mtrain_process, args\u001b[39m=\u001b[39m[q, weights, train_loader, privacy_engine, \u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfastcep/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m p\u001b[39m.\u001b[39mstart()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bfastcep/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m weights, privacy_engine \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfastcep/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m p\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bfastcep/home/lcorbucci/pistacchio-fl-simulator/pistacchio_simulator/mnist_test.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m set_params(model, weights)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pistacchio-fl-simulator-XKOu9Fs5-py3.10/lib/python3.10/site-packages/multiprocess/queues.py:106\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m block \u001b[39mand\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock:\n\u001b[0;32m--> 106\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    107\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sem\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pistacchio-fl-simulator-XKOu9Fs5-py3.10/lib/python3.10/site-packages/multiprocess/connection.py:219\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m maxlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m maxlength \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnegative maxlength\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 219\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes(maxlength)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pistacchio-fl-simulator-XKOu9Fs5-py3.10/lib/python3.10/site-packages/multiprocess/connection.py:417\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 417\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    418\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    419\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/pistacchio-fl-simulator-XKOu9Fs5-py3.10/lib/python3.10/site-packages/multiprocess/connection.py:382\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    380\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    381\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    383\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocess import Process, Queue\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_parameters(model):\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_params(model: torch.nn.ModuleList, params):\n",
    "    \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), params)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "model = MnistNet().to(device)\n",
    "\n",
    "weights = get_parameters(model)\n",
    "privacy_engine = PrivacyEngine(accountant=\"rdp\")\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weights, train_loader, privacy_engine, 0])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weigts, device, privacy_engine, 1])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)\n",
    "\n",
    "q = Queue()\n",
    "p = Process(target=train_process, args=[q, weigts, device, privacy_engine, 1])\n",
    "p.start()\n",
    "weights, privacy_engine = q.get()\n",
    "p.join()\n",
    "\n",
    "set_params(model, weights)\n",
    "\n",
    "weigts = get_parameters(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistacchio-fl-simulator-XKOu9Fs5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
