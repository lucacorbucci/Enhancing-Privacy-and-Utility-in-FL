{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# matpllitb\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACSIncomeSplit:\n",
    "    def split_indexes_iid(num_clients, num_samples):\n",
    "        indexes = np.arange(num_samples)\n",
    "        np.random.shuffle(indexes)\n",
    "        return np.array_split(indexes, num_clients)\n",
    "\n",
    "    def split_indexes_non_iid(labels_and_grops_indexes, num_clients, alpha):\n",
    "        labels = []\n",
    "        groups = []\n",
    "        indexes = {}\n",
    "        for label, group, _ in labels_and_grops_indexes:\n",
    "            labels.append(label)\n",
    "            groups.append(group)\n",
    "\n",
    "        label_and_group = list(zip(labels, groups))\n",
    "        for index, (label, group) in enumerate(label_and_group):\n",
    "            if (label, group) not in indexes:\n",
    "                indexes[(label, group)] = []\n",
    "            indexes[(label, group)].append(index)\n",
    "\n",
    "        possible_labels_and_groups = list(set(label_and_group))\n",
    "        # generate len(possible_labels_and_groups) dirichlet distributions with alpha\n",
    "        # we need a distribution for each possible (label, group) and for each distribution\n",
    "        # we need to have a probability for each client\n",
    "        distributions = []\n",
    "        for partition in range(len(possible_labels_and_groups)):\n",
    "            distribution = np.random.dirichlet(num_clients * [alpha], size=1)\n",
    "            distributions.append(distribution[0])\n",
    "\n",
    "        # now we sample from each of the distributions to get the indexes for each client\n",
    "        # we do not want to sample the same index twice\n",
    "        clients_indexes = []\n",
    "        for client in range(num_clients):\n",
    "            client_indexes = []\n",
    "            for partition in range(len(possible_labels_and_groups)):\n",
    "                indexes_for_partition = indexes[possible_labels_and_groups[partition]]\n",
    "                num_samples = int(\n",
    "                    distributions[partition][client] * len(indexes_for_partition)\n",
    "                )\n",
    "                samples = np.random.choice(\n",
    "                    indexes_for_partition, num_samples, replace=False\n",
    "                )\n",
    "                client_indexes.extend(samples)\n",
    "            clients_indexes.append(client_indexes)\n",
    "\n",
    "        return clients_indexes\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x, z, y):\n",
    "        \"\"\"\n",
    "        Initialize the custom dataset with x (features), z (sensitive values), and y (targets).\n",
    "\n",
    "        Args:\n",
    "        x (list of tensors): List of input feature tensors.\n",
    "        z (list): List of sensitive values.\n",
    "        y (list): List of target values.\n",
    "        \"\"\"\n",
    "        self.samples = x\n",
    "        self.sensitive_features = z\n",
    "        self.sensitive_attribute = z\n",
    "        self.gender = z\n",
    "        self.classes = y\n",
    "        self.targets = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single data point from the dataset.\n",
    "\n",
    "        Args:\n",
    "        idx (int): Index to retrieve the data point.\n",
    "\n",
    "        Returns:\n",
    "        sample (dict): A dictionary containing 'x', 'z', and 'y'.\n",
    "        \"\"\"\n",
    "        x_sample = self.samples[idx]\n",
    "        z_sample = self.sensitive_features[idx]\n",
    "        y_sample = self.targets[idx]\n",
    "\n",
    "        return x_sample, z_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 51\n",
    "max_len_public = 0.5\n",
    "num_clients = 5\n",
    "\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "public_private_indexes = []\n",
    "public_private_indexes_validation = []\n",
    "\n",
    "clusters_test_data = []\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    dataframe = np.load(\n",
    "        f\"./data/income/federated/{cluster}/income_dataframes_{cluster}.npy\"\n",
    "    )\n",
    "    income_groups = np.load(\n",
    "        f\"./data/income/federated/{cluster}/income_groups_{cluster}.npy\"\n",
    "    )\n",
    "    income_labels = np.load(\n",
    "        f\"./data/income/federated/{cluster}/income_labels_{cluster}.npy\"\n",
    "    )\n",
    "\n",
    "    # sample from a numpy array\n",
    "\n",
    "    test_indexes = np.arange(len(dataframe))\n",
    "    num_samples_test = int(len(dataframe) * test_size)\n",
    "    sampled_indexes_test = np.random.choice(\n",
    "        test_indexes, num_samples_test, replace=False\n",
    "    )\n",
    "\n",
    "    dataframe_test = dataframe[sampled_indexes_test]\n",
    "    income_groups_test = income_groups[sampled_indexes_test]\n",
    "    income_labels_test = income_labels[sampled_indexes_test]\n",
    "    test_dataset_size = len(dataframe_test)\n",
    "    all_indexes_test = np.arange(len(dataframe_test))\n",
    "\n",
    "    cluster_test_data = TabularDataset(\n",
    "        dataframe_test, income_groups_test, income_labels_test\n",
    "    )\n",
    "    clusters_test_data.append((dataframe_test, income_groups_test, income_labels_test))\n",
    "    torch.save(\n",
    "        cluster_test_data, f\"./data/income/federated_data/test_cluster_{cluster}.pt\"\n",
    "    )\n",
    "\n",
    "    # remove the sampled_indexes_test from the original numpy array\n",
    "    dataframe = np.delete(dataframe, sampled_indexes_test, axis=0)\n",
    "    income_groups = np.delete(income_groups, sampled_indexes_test)\n",
    "    income_labels = np.delete(income_labels, sampled_indexes_test)\n",
    "\n",
    "    dataset_test = TabularDataset(\n",
    "        dataframe_test, income_groups_test, income_labels_test\n",
    "    )\n",
    "\n",
    "    labels_and_groups_indexes = [\n",
    "        (lab, group, index)\n",
    "        for lab, group, index in zip(\n",
    "            list(income_labels),\n",
    "            list(income_groups),\n",
    "            range(len(income_labels)),\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    client_indexes = ACSIncomeSplit.split_indexes_non_iid(\n",
    "        labels_and_groups_indexes, num_clients=num_clients, alpha=5\n",
    "    )\n",
    "    labels_and_group_indexes_public_private = []\n",
    "    # for each client we get the labels and the groups because we need to\n",
    "    # create the public and private datasets\n",
    "    for client in client_indexes:\n",
    "        label = income_labels[client]\n",
    "        group = income_groups[client]\n",
    "        index = client\n",
    "        labels_and_group_indexes_public_private.append(\n",
    "            [(lab, group, ind) for lab, group, ind in zip(label, group, index)]\n",
    "        )\n",
    "\n",
    "    tmp_public_private_indexes = []\n",
    "    tmp_public_private_indexes_validation = []\n",
    "    for client_id, client in enumerate(labels_and_group_indexes_public_private):\n",
    "        total_size_data = len(client)\n",
    "        indexes = [index for (label, group, index) in client]\n",
    "        public_size_data = int(total_size_data * max_len_public)\n",
    "        private_size_data = total_size_data - public_size_data\n",
    "        # random sample public_size_data samples from the indexes of the client\n",
    "        # based on a dirichlet distribution\n",
    "        distribution = np.random.dirichlet(private_size_data * [1], size=1)\n",
    "        # private_indexes = np.random.choice(\n",
    "        #     indexes, private_size_data, replace=False, p=distribution[0]\n",
    "        # )\n",
    "        private_indexes = np.random.choice(indexes, private_size_data, replace=False)\n",
    "        private_indexes_validation = np.random.choice(\n",
    "            private_indexes, int(private_size_data * validation_size), replace=False\n",
    "        )\n",
    "        private_indexes = [index for index in indexes if index not in private_indexes]\n",
    "\n",
    "        private_data = dataframe[private_indexes]\n",
    "        private_groups = income_groups[private_indexes]\n",
    "        private_labels = income_labels[private_indexes]\n",
    "        private_data_validation = dataframe[private_indexes_validation]\n",
    "        private_groups_validation = income_groups[private_indexes_validation]\n",
    "        private_labels_validation = income_labels[private_indexes_validation]\n",
    "\n",
    "        private_dataset = TabularDataset(private_data, private_groups, private_labels)\n",
    "        private_dataset_validation = TabularDataset(\n",
    "            private_data_validation,\n",
    "            private_groups_validation,\n",
    "            private_labels_validation,\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            private_dataset,\n",
    "            f\"./data/income/federated_data/cluster_{cluster}_node_{client_id}_private_train.pt\",\n",
    "        )\n",
    "        torch.save(\n",
    "            private_dataset_validation,\n",
    "            f\"./data/income/federated_data/cluster_{cluster}_node_{client_id}_private_validation.pt\",\n",
    "        )\n",
    "\n",
    "        public_indexes = [index for index in indexes if index not in private_indexes]\n",
    "        public_indexes_validation = np.random.choice(\n",
    "            public_indexes, int(public_size_data * validation_size), replace=False\n",
    "        )\n",
    "        public_indexes = [index for index in indexes if index not in public_indexes]\n",
    "\n",
    "        public_data = dataframe[public_indexes]\n",
    "        public_groups = income_groups[public_indexes]\n",
    "        public_labels = income_labels[public_indexes]\n",
    "        public_data_validation = dataframe[public_indexes_validation]\n",
    "        public_groups_validation = income_groups[public_indexes_validation]\n",
    "        public_labels_validation = income_labels[public_indexes_validation]\n",
    "\n",
    "        public_dataset = TabularDataset(public_data, public_groups, public_labels)\n",
    "        public_dataset_validation = TabularDataset(\n",
    "            public_data_validation, public_groups_validation, public_labels_validation\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            public_dataset,\n",
    "            f\"./data/income/federated_data/cluster_{cluster}_node_{client_id}_public_train.pt\",\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            public_dataset_validation,\n",
    "            f\"./data/income/federated_data/cluster_{cluster}_node_{client_id}_public_validation.pt\",\n",
    "        )\n",
    "\n",
    "        # new\n",
    "        indexes_test = np.random.choice(\n",
    "            all_indexes_test, int(test_dataset_size / num_clients), replace=False\n",
    "        )\n",
    "        all_indexes_test = [\n",
    "            index for index in all_indexes_test if index not in indexes_test\n",
    "        ]\n",
    "        data_test = dataframe_test[indexes_test]\n",
    "        groups_test = income_groups_test[indexes_test]\n",
    "        labels_test = income_labels_test[indexes_test]\n",
    "\n",
    "        test_node_cluster = TabularDataset(data_test, groups_test, labels_test)\n",
    "\n",
    "        torch.save(\n",
    "            test_node_cluster,\n",
    "            f\"./data/income/federated_data/test_node_{client_id}_cluster_{cluster}.pt\",\n",
    "        )\n",
    "\n",
    "        tmp_public_private_indexes.append((public_indexes, private_indexes))\n",
    "        tmp_public_private_indexes_validation.append(\n",
    "            (public_indexes_validation, private_indexes_validation)\n",
    "        )\n",
    "\n",
    "    public_private_indexes.append(tmp_public_private_indexes)\n",
    "    public_private_indexes_validation.append(tmp_public_private_indexes_validation)\n",
    "\n",
    "\n",
    "data = [data for (data, _, _) in clusters_test_data]\n",
    "# concatenate the numpy arrays\n",
    "data = np.concatenate(data, axis=0)\n",
    "groups = [groups for (_, groups, _) in clusters_test_data]\n",
    "groups = np.concatenate(groups, axis=0)\n",
    "labels = [labels for (_, _, labels) in clusters_test_data]\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "test_dataset = TabularDataset(data, groups, labels)\n",
    "torch.save(test_dataset, \"./data/income/federated_data/server_test_set.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id, cluster in enumerate(public_private_indexes):\n",
    "    for client_id, client in enumerate(cluster):\n",
    "        dataframe = np.load(\n",
    "            f\"./data/income/federated/{cluster_id}/income_dataframes_{cluster_id}.npy\"\n",
    "        )\n",
    "        income_groups = np.load(\n",
    "            f\"./data/income/federated/{cluster_id}/income_groups_{cluster_id}.npy\"\n",
    "        )\n",
    "        income_labels = np.load(\n",
    "            f\"./data/income/federated/{cluster_id}/income_labels_{cluster_id}.npy\"\n",
    "        )\n",
    "\n",
    "        public_indexes, private_indexes = client\n",
    "        public_data = dataframe[public_indexes]\n",
    "        private_data = dataframe[private_indexes]\n",
    "        public_groups = income_groups[public_indexes]\n",
    "        private_groups = income_groups[private_indexes]\n",
    "        public_labels = income_labels[public_indexes]\n",
    "        private_labels = income_labels[private_indexes]\n",
    "        public_dataset = TabularDataset(public_data, public_groups, public_labels)\n",
    "        private_dataset = TabularDataset(private_data, private_groups, private_labels)\n",
    "\n",
    "        torch.save(\n",
    "            public_dataset,\n",
    "            f\"./data/income/federated/{cluster_id}/public_dataset_{client_id}.pt\",\n",
    "        )\n",
    "        torch.save(\n",
    "            private_dataset,\n",
    "            f\"./data/income/federated/{cluster_id}/private_dataset_{client_id}.pt\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataframe = np.load(\"./data/income/federated/0/income_dataframes_0.npy\")\n",
    "income_groups = np.load(\"./data/income/federated/0/income_groups_0.npy\")\n",
    "income_labels = np.load(\"./data/income/federated/0/income_labels_0.npy\")\n",
    "max_len_public = 0.2\n",
    "labels_and_groups = [\n",
    "    (lab, group) for lab, group in zip(list(income_labels), list(income_groups))\n",
    "]\n",
    "labels_and_groups_indexes = [\n",
    "    (lab, group, index)\n",
    "    for lab, group, index in zip(\n",
    "        list(income_labels), list(income_groups), range(len(income_labels))\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_iid = ACSIncomeSplit.split_indexes_iid(10, len(dataframe))\n",
    "# split the data, labels and groups into 10 clients using the indexes from split_iid\n",
    "dataframe_splits_private = [\n",
    "    dataframe[split_iid[i][0 : int(max_len_public * len(split_iid[i]))]]\n",
    "    for i in range(len(split_iid))\n",
    "]\n",
    "labels_splits_private = [\n",
    "    income_labels[split_iid[i][0 : int(max_len_public * len(split_iid[i]))]]\n",
    "    for i in range(len(split_iid))\n",
    "]\n",
    "groups_splits_private = [\n",
    "    income_groups[split_iid[i][0 : int(max_len_public * len(split_iid[i]))]]\n",
    "    for i in range(len(split_iid))\n",
    "]\n",
    "\n",
    "dataframe_splits_public = [\n",
    "    dataframe[split_iid[i][int(max_len_public * len(split_iid[i])) :]]\n",
    "    for i in range(len(split_iid))\n",
    "]\n",
    "labels_splits_public = [\n",
    "    income_labels[split_iid[i][int(max_len_public * len(split_iid[i])) :]]\n",
    "    for i in range(len(split_iid))\n",
    "]\n",
    "groups_splits_public = [\n",
    "    income_groups[split_iid[i][int(max_len_public * len(split_iid[i])) :]]\n",
    "    for i in range(len(split_iid))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_indexes = ACSIncomeSplit.split_indexes_non_iid(labels_and_groups_indexes, 10, 5)\n",
    "# plot a bar plot of the amount of (labels, groups) for each client\n",
    "# using a bar plot and matplotlib. On x axis I want the clients\n",
    "# and on the y axis I want the amount of (labels, groups) for each client\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "labels_groups_per_clients = []\n",
    "labels = np.array(income_labels)\n",
    "groups = np.array(income_groups)\n",
    "counters = []\n",
    "for client_index in clients_indexes:\n",
    "    labels_groups_per_clients.append(\n",
    "        [(lab, group) for lab, group in zip(labels[client_index], groups[client_index])]\n",
    "    )\n",
    "    counters.append(Counter(labels_groups_per_clients[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_group_0_0 = [counter[(0, 0)] for counter in counters]\n",
    "counter_group_0_1 = [counter[(0, 1)] for counter in counters]\n",
    "counter_group_1_0 = [counter[(1, 0)] for counter in counters]\n",
    "counter_group_1_1 = [counter[(1, 1)] for counter in counters]\n",
    "\n",
    "# plot a barplot with counter_group_0_0, counter_group_0_1, counter_group_1_0, counter_group_1_1\n",
    "# for each client in the same plot\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.bar(range(len(counter_group_0_0)), counter_group_0_0)\n",
    "plt.bar(range(len(counter_group_0_1)), counter_group_0_1, bottom=counter_group_0_0)\n",
    "plt.bar(\n",
    "    range(len(counter_group_1_0)),\n",
    "    counter_group_1_0,\n",
    "    bottom=[sum(x) for x in zip(counter_group_0_0, counter_group_0_1)],\n",
    ")\n",
    "plt.bar(\n",
    "    range(len(counter_group_1_1)),\n",
    "    counter_group_1_1,\n",
    "    bottom=[\n",
    "        sum(x) for x in zip(counter_group_0_0, counter_group_0_1, counter_group_1_0)\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Client\")\n",
    "plt.ylabel(\"Amount of samples\")\n",
    "plt.title(\"Samples for each group (target/sensitive Value) per client\")\n",
    "plt.legend([\"0,0\", \"0,1\", \"1,0\", \"1,1\"])\n",
    "# font size 20\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_and_group_indexes_public_private = []\n",
    "for client in clients_indexes:\n",
    "    label = income_labels[client]\n",
    "    group = income_groups[client]\n",
    "    index = client\n",
    "    labels_and_group_indexes_public_private.append(\n",
    "        [(lab, group, ind) for lab, group, ind in zip(label, group, index)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_private_indexes = []\n",
    "for client in labels_and_group_indexes_public_private:\n",
    "    total_size_data = len(client)\n",
    "    indexes = [index for (label, group, index) in client]\n",
    "    public_size_data = int(total_size_data * public_size)\n",
    "    private_size_data = total_size_data - public_size_data\n",
    "    # random sample public_size_data samples from the indexes of the client\n",
    "    # based on a dirichlet distribution\n",
    "    distribution = np.random.dirichlet(private_size_data * [1], size=1)\n",
    "    # private_indexes = np.random.choice(\n",
    "    #     indexes, private_size_data, replace=False, p=distribution[0]\n",
    "    # )\n",
    "    private_indexes = np.random.choice(indexes, private_size_data, replace=False)\n",
    "    public_indexes = [index for index in indexes if index not in private_indexes]\n",
    "\n",
    "    public_private_indexes.append((public_indexes, private_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for public, private in public_private_indexes:\n",
    "    labels_groups_per_clients = []\n",
    "    labels = np.array(income_labels)\n",
    "    groups = np.array(income_groups)\n",
    "    counters = []\n",
    "\n",
    "    labels_groups_per_clients.append(\n",
    "        [(lab, group) for lab, group in zip(labels[public], groups[public])]\n",
    "    )\n",
    "    counters.append(Counter(labels_groups_per_clients[-1]))\n",
    "\n",
    "    labels_groups_per_clients.append(\n",
    "        [(lab, group) for lab, group in zip(labels[private], groups[private])]\n",
    "    )\n",
    "    counters.append(Counter(labels_groups_per_clients[-1]))\n",
    "\n",
    "    counter_group_0_0 = [counter[(0, 0)] for counter in counters]\n",
    "    counter_group_0_1 = [counter[(0, 1)] for counter in counters]\n",
    "    counter_group_1_0 = [counter[(1, 0)] for counter in counters]\n",
    "    counter_group_1_1 = [counter[(1, 1)] for counter in counters]\n",
    "\n",
    "    # plot a barplot with counter_group_0_0, counter_group_0_1, counter_group_1_0, counter_group_1_1\n",
    "    # for each client in the same plot\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    plt.bar(range(len(counter_group_0_0)), counter_group_0_0)\n",
    "    plt.bar(range(len(counter_group_0_1)), counter_group_0_1, bottom=counter_group_0_0)\n",
    "    plt.bar(\n",
    "        range(len(counter_group_1_0)),\n",
    "        counter_group_1_0,\n",
    "        bottom=[sum(x) for x in zip(counter_group_0_0, counter_group_0_1)],\n",
    "    )\n",
    "    plt.bar(\n",
    "        range(len(counter_group_1_1)),\n",
    "        counter_group_1_1,\n",
    "        bottom=[\n",
    "            sum(x) for x in zip(counter_group_0_0, counter_group_0_1, counter_group_1_0)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Client\")\n",
    "    plt.ylabel(\"Amount of samples\")\n",
    "    plt.title(\"Samples for each group (target/sensitive Value) per client\")\n",
    "    plt.legend([\"0,0\", \"0,1\", \"1,0\", \"1,1\"])\n",
    "    # font size 20\n",
    "    plt.rcParams.update({\"font.size\": 20})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clients_indexes = split_indexes_non_iid(\n",
    "#     labels_and_group_indexes_public_private[0], 2, 5\n",
    "# )\n",
    "# print(clients_indexes)\n",
    "\n",
    "# labels_groups_per_clients = []\n",
    "# labels = np.array(income_labels)\n",
    "# groups = np.array(income_groups)\n",
    "# counters = []\n",
    "# for client_index in clients_indexes:\n",
    "#     labels_groups_per_clients.append(\n",
    "#         [(lab, group) for lab, group in zip(labels[client_index], groups[client_index])]\n",
    "#     )\n",
    "#     counters.append(Counter(labels_groups_per_clients[-1]))\n",
    "\n",
    "\n",
    "# print(len(labels_groups_per_clients))\n",
    "\n",
    "# counter_group_0_0 = [counter[(0, 0)] for counter in counters]\n",
    "# counter_group_0_1 = [counter[(0, 1)] for counter in counters]\n",
    "# counter_group_1_0 = [counter[(1, 0)] for counter in counters]\n",
    "# counter_group_1_1 = [counter[(1, 1)] for counter in counters]\n",
    "\n",
    "# # plot a barplot with counter_group_0_0, counter_group_0_1, counter_group_1_0, counter_group_1_1\n",
    "# # for each client in the same plot\n",
    "# plt.figure(figsize=(20, 8))\n",
    "\n",
    "# plt.bar(range(len(counter_group_0_0)), counter_group_0_0)\n",
    "# plt.bar(range(len(counter_group_0_1)), counter_group_0_1, bottom=counter_group_0_0)\n",
    "# plt.bar(\n",
    "#     range(len(counter_group_1_0)),\n",
    "#     counter_group_1_0,\n",
    "#     bottom=[sum(x) for x in zip(counter_group_0_0, counter_group_0_1)],\n",
    "# )\n",
    "# plt.bar(\n",
    "#     range(len(counter_group_1_1)),\n",
    "#     counter_group_1_1,\n",
    "#     bottom=[\n",
    "#         sum(x) for x in zip(counter_group_0_0, counter_group_0_1, counter_group_1_0)\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.xlabel(\"Client\")\n",
    "# plt.ylabel(\"Amount of samples\")\n",
    "# plt.title(\"Samples for each group (target/sensitive Value) per client\")\n",
    "# plt.legend([\"0,0\", \"0,1\", \"1,0\", \"1,1\"])\n",
    "# # font size 20\n",
    "# plt.rcParams.update({\"font.size\": 20})\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for client_data in labels_and_group_indexes_public_private:\n",
    "#     clients_indexes = split_indexes_non_iid(client_data, 2, 5)\n",
    "#     print(clients_indexes)\n",
    "\n",
    "#     labels_groups_per_clients = []\n",
    "#     labels = np.array(income_labels)\n",
    "#     groups = np.array(income_groups)\n",
    "#     counters = []\n",
    "#     for client_index in clients_indexes:\n",
    "#         labels_groups_per_clients.append(\n",
    "#             [(lab, group) for lab, group in zip(labels[client_index], groups[client_index])]\n",
    "#         )\n",
    "\n",
    "#     counters.append(Counter(labels_groups_per_clients[-1]))\n",
    "#     counter_group_0_0 = [counter[(0, 0)] for counter in counters]\n",
    "#     counter_group_0_1 = [counter[(0, 1)] for counter in counters]\n",
    "#     counter_group_1_0 = [counter[(1, 0)] for counter in counters]\n",
    "#     counter_group_1_1 = [counter[(1, 1)] for counter in counters]\n",
    "\n",
    "#     # plot a barplot with counter_group_0_0, counter_group_0_1, counter_group_1_0, counter_group_1_1\n",
    "#     # for each client in the same plot\n",
    "#     plt.figure(figsize=(20, 8))\n",
    "\n",
    "#     plt.bar(range(len(counter_group_0_0)), counter_group_0_0)\n",
    "#     plt.bar(range(len(counter_group_0_1)), counter_group_0_1, bottom=counter_group_0_0)\n",
    "#     plt.bar(\n",
    "#         range(len(counter_group_1_0)),\n",
    "#         counter_group_1_0,\n",
    "#         bottom=[sum(x) for x in zip(counter_group_0_0, counter_group_0_1)],\n",
    "#     )\n",
    "#     plt.bar(\n",
    "#         range(len(counter_group_1_1)),\n",
    "#         counter_group_1_1,\n",
    "#         bottom=[\n",
    "#             sum(x) for x in zip(counter_group_0_0, counter_group_0_1, counter_group_1_0)\n",
    "#         ],\n",
    "#     )\n",
    "\n",
    "\n",
    "#     plt.xlabel(\"Client\")\n",
    "#     plt.ylabel(\"Amount of samples\")\n",
    "#     plt.title(\"Samples for each group (target/sensitive Value) per client\")\n",
    "#     plt.legend([\"0,0\", \"0,1\", \"1,0\", \"1,1\"])\n",
    "#     # font size 20\n",
    "#     plt.rcParams.update({\"font.size\": 20})\n",
    "#     plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pistacchio-fl-simulator-XKOu9Fs5-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
