{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area_0\",\n",
    "    \"Wilderness_Area_1\",\n",
    "    \"Wilderness_Area_2\",\n",
    "    \"Wilderness_Area_3\",\n",
    "    \"Soil_Type_0\",\n",
    "    \"Soil_Type_1\",\n",
    "    \"Soil_Type_2\",\n",
    "    \"Soil_Type_3\",\n",
    "    \"Soil_Type_4\",\n",
    "    \"Soil_Type_5\",\n",
    "    \"Soil_Type_6\",\n",
    "    \"Soil_Type_7\",\n",
    "    \"Soil_Type_8\",\n",
    "    \"Soil_Type_9\",\n",
    "    \"Soil_Type_10\",\n",
    "    \"Soil_Type_11\",\n",
    "    \"Soil_Type_12\",\n",
    "    \"Soil_Type_13\",\n",
    "    \"Soil_Type_14\",\n",
    "    \"Soil_Type_15\",\n",
    "    \"Soil_Type_16\",\n",
    "    \"Soil_Type_17\",\n",
    "    \"Soil_Type_18\",\n",
    "    \"Soil_Type_19\",\n",
    "    \"Soil_Type_20\",\n",
    "    \"Soil_Type_21\",\n",
    "    \"Soil_Type_22\",\n",
    "    \"Soil_Type_23\",\n",
    "    \"Soil_Type_24\",\n",
    "    \"Soil_Type_25\",\n",
    "    \"Soil_Type_26\",\n",
    "    \"Soil_Type_27\",\n",
    "    \"Soil_Type_28\",\n",
    "    \"Soil_Type_29\",\n",
    "    \"Soil_Type_30\",\n",
    "    \"Soil_Type_31\",\n",
    "    \"Soil_Type_32\",\n",
    "    \"Soil_Type_33\",\n",
    "    \"Soil_Type_34\",\n",
    "    \"Soil_Type_35\",\n",
    "    \"Soil_Type_36\",\n",
    "    \"Soil_Type_37\",\n",
    "    \"Soil_Type_38\",\n",
    "    \"Soil_Type_39\",\n",
    "    \"Cover_type\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/covertype/covtype.data\", names=column_names, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <th>Cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_31  Soil_Type_32  \\\n",
       "0                                6279  ...             0             0   \n",
       "1                                6225  ...             0             0   \n",
       "2                                6121  ...             0             0   \n",
       "3                                6211  ...             0             0   \n",
       "4                                6172  ...             0             0   \n",
       "\n",
       "   Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  Soil_Type_37  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Soil_Type_38  Soil_Type_39  Cover_type  \n",
       "0             0             0           5  \n",
       "1             0             0           5  \n",
       "2             0             0           2  \n",
       "3             0             0           2  \n",
       "4             0             0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [0 if item == 7 else item for item in list(data[\"Cover_type\"])]\n",
    "data[\"Cover_type\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 9493, 2: 283301, 1: 211840, 0: 20510, 3: 35754, 6: 17367, 4: 2747})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(list(data[\"Cover_type\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/covertype/covtype.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this function to retrieve X, X, y arrays for training ML models\n",
    "@staticmethod\n",
    "def dataset_to_numpy(\n",
    "    _df,\n",
    "    _feature_cols: list,\n",
    "    _metadata: dict,\n",
    "    num_sensitive_features: int = 1,\n",
    "    sensitive_features_last: bool = True,\n",
    "):\n",
    "    \"\"\"Args:\n",
    "    _df: pandas dataframe\n",
    "    _feature_cols: list of feature column names\n",
    "    _metadata: dictionary with metadata\n",
    "    num_sensitive_features: number of sensitive features to use\n",
    "    sensitive_features_last: if True, then sensitive features are encoded as last columns\n",
    "    \"\"\"\n",
    "\n",
    "    # transform features to 1-hot\n",
    "    _X = _df[_feature_cols]\n",
    "    # take sensitive features separately\n",
    "    print(\n",
    "        f'Using {_metadata[\"protected_atts\"][:num_sensitive_features]} as sensitive feature(s).'\n",
    "    )\n",
    "    if num_sensitive_features > len(_metadata[\"protected_atts\"]):\n",
    "        num_sensitive_features = len(_metadata[\"protected_atts\"])\n",
    "    _Z = _X[_metadata[\"protected_atts\"][:num_sensitive_features]]\n",
    "    _X = _X.drop(columns=_metadata[\"protected_atts\"][:num_sensitive_features])\n",
    "    # 1-hot encode and scale features\n",
    "    if \"dummy_cols\" in _metadata.keys():\n",
    "        dummy_cols = _metadata[\"dummy_cols\"]\n",
    "    else:\n",
    "        dummy_cols = None\n",
    "    _X2 = pd.get_dummies(_X, columns=dummy_cols, drop_first=False)\n",
    "    esc = MinMaxScaler()\n",
    "    _X = esc.fit_transform(_X)\n",
    "\n",
    "    # current implementation assumes each sensitive feature is binary\n",
    "    for i, tmp in enumerate(_metadata[\"protected_atts\"][:num_sensitive_features]):\n",
    "        assert len(_Z[tmp].unique()) == 2, \"Sensitive feature is not binary!\"\n",
    "\n",
    "    # 1-hot sensitive features, (optionally) swap ordering so privileged class feature == 1 is always last, preceded by the corresponding unprivileged feature\n",
    "    _Z2 = pd.get_dummies(_Z, columns=_Z.columns, drop_first=False)\n",
    "    # print(_Z2.head(), _Z2.shape)\n",
    "    if sensitive_features_last:\n",
    "        for i, tmp in enumerate(_Z.columns):\n",
    "            assert (\n",
    "                _metadata[\"protected_att_values\"][i] in _Z[tmp].unique()\n",
    "            ), \"Protected attribute value not found in data!\"\n",
    "            if not np.allclose(float(_metadata[\"protected_att_values\"][i]), 0):\n",
    "                # swap columns\n",
    "                _Z2.iloc[:, [2 * i, 2 * i + 1]] = _Z2.iloc[:, [2 * i + 1, 2 * i]]\n",
    "    # change booleans to floats\n",
    "    # _Z2 = _Z2.astype(float)\n",
    "    # _Z = _Z2.to_numpy()\n",
    "    _y = _df[_metadata[\"target_variable\"]].values\n",
    "    return _X, np.array([sv[0] for sv in _Z.values]), _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_covtype = {\n",
    "    \"name\": \"Covertype\",\n",
    "    \"target_variable\": \"Cover_type\",\n",
    "    \"protected_atts\": [\"Soil_Type_0\"],\n",
    "    \"protected_att_values\": [0],\n",
    "    \"protected_att_descriptions\": [\"Gender = Female\"],\n",
    "    \"protected_att_descriptions\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ['Soil_Type_0'] as sensitive feature(s).\n"
     ]
    }
   ],
   "source": [
    "numpy_dataset = dataset_to_numpy(\n",
    "    _df=data,\n",
    "    _feature_cols=column_names,\n",
    "    _metadata=metadata_covtype,\n",
    "    num_sensitive_features=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numpy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pistacchio_simulator.FederatedDataset.Utils.custom_dataset import (\n",
    "    TabularDataset,\n",
    ")\n",
    "\n",
    "x = numpy_dataset[0]\n",
    "y = numpy_dataset[2]\n",
    "z = numpy_dataset[1]\n",
    "\n",
    "xyz = list(zip(x, y, z))\n",
    "random.shuffle(xyz)\n",
    "x, y, z = zip(*xyz)\n",
    "train_size = int(len(y) * 0.8)\n",
    "\n",
    "x_train = np.array(x[:train_size])\n",
    "x_test = np.array(x[train_size:])\n",
    "y_train = np.array(y[:train_size])\n",
    "y_test = np.array(y[train_size:])\n",
    "z_train = np.array(z[:train_size])\n",
    "z_test = np.array(z[train_size:])\n",
    "\n",
    "train_dataset = TabularDataset(\n",
    "    x=np.hstack((x_train, np.ones((x_train.shape[0], 1)))).astype(np.float32),\n",
    "    z=z_train.astype(np.float32),\n",
    "    y=y_train.astype(np.float32),\n",
    ")\n",
    "\n",
    "test_dataset = TabularDataset(\n",
    "    x=np.hstack((x_test, np.ones((x_test.shape[0], 1)))).astype(np.float32),\n",
    "    z=z_test.astype(np.float32),\n",
    "    y=y_test.astype(np.float32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @staticmethod\n",
    "# def download_covertype() -> (\n",
    "#     Tuple[\n",
    "#         torch.utils.data.DataLoader,\n",
    "#         torch.utils.data.DataLoader,\n",
    "#     ]\n",
    "# ):\n",
    "#     \"\"\"This function downloads the adult dataset.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#         Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "#         the train and test dataset\n",
    "#     \"\"\"\n",
    "#     data = pd.read_fwf(\"../data/covertype/covtype.data\")\n",
    "\n",
    "#     covtype_df = pd.DataFrame(data[0]).astype(\"int32\")\n",
    "\n",
    "#     dutch_df[\"sex_binary\"] = np.where(dutch_df[\"sex\"] == 1, 1, 0)\n",
    "#     dutch_df[\"occupation_binary\"] = np.where(dutch_df[\"occupation\"] >= 300, 1, 0)\n",
    "\n",
    "#     del dutch_df[\"sex\"]\n",
    "#     del dutch_df[\"occupation\"]\n",
    "\n",
    "#     dutch_df_feature_columns = [\n",
    "#         \"age\",\n",
    "#         \"household_position\",\n",
    "#         \"household_size\",\n",
    "#         \"prev_residence_place\",\n",
    "#         \"citizenship\",\n",
    "#         \"country_birth\",\n",
    "#         \"edu_level\",\n",
    "#         \"economic_status\",\n",
    "#         \"cur_eco_activity\",\n",
    "#         \"Marital_status\",\n",
    "#         \"sex_binary\",\n",
    "#     ]\n",
    "\n",
    "#     metadata_dutch = {\n",
    "#         \"name\": \"Dutch census\",\n",
    "#         \"code\": [\"DU1\"],\n",
    "#         \"protected_atts\": [\"sex_binary\"],\n",
    "#         \"protected_att_values\": [0],\n",
    "#         \"protected_att_descriptions\": [\"Gender = Female\"],\n",
    "#         \"target_variable\": \"occupation_binary\",\n",
    "#     }\n",
    "\n",
    "#     tmp = DatasetDownloader.dataset_to_numpy(\n",
    "#         dutch_df, dutch_df_feature_columns, metadata_dutch, num_sensitive_features=1\n",
    "#     )\n",
    "\n",
    "#     x = tmp[0]\n",
    "#     y = tmp[2]\n",
    "#     z = tmp[1]\n",
    "\n",
    "#     xyz = list(zip(x, y, z))\n",
    "#     random.shuffle(xyz)\n",
    "#     x, y, z = zip(*xyz)\n",
    "#     train_size = int(len(y) * 0.8)\n",
    "\n",
    "#     x_train = np.array(x[:train_size])\n",
    "#     x_test = np.array(x[train_size:])\n",
    "#     y_train = np.array(y[:train_size])\n",
    "#     y_test = np.array(y[train_size:])\n",
    "#     z_train = np.array(z[:train_size])\n",
    "#     z_test = np.array(z[train_size:])\n",
    "\n",
    "#     train_dataset = TabularDataset(\n",
    "#         x=np.hstack((x_train, np.ones((x_train.shape[0], 1)))).astype(np.float32),\n",
    "#         z=z_train.astype(np.float32),\n",
    "#         y=y_train.astype(np.float32),\n",
    "#     )\n",
    "\n",
    "#     test_dataset = TabularDataset(\n",
    "#         x=np.hstack((x_test, np.ones((x_test.shape[0], 1)))).astype(np.float32),\n",
    "#         z=z_test.astype(np.float32),\n",
    "#         y=y_test.astype(np.float32),\n",
    "#     )\n",
    "\n",
    "#     return train_dataset, test_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
